{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KD.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMkiKx9Qqw2azgbFZrAuIes",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KeremAydin98/knowledge-distillation/blob/main/KD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "RsiEV3kF5ipI"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Distiller(tf.keras.models.Model):\n",
        "  \"\"\"\n",
        "  For a distiller we need:\n",
        "  - A trained teacher model\n",
        "  - A student model to train \n",
        "  - A student loss function on the difference between student predictions and ground \n",
        "  truth\n",
        "  - A distillation loss function, along with a temperature, on the difference between \n",
        "  the soft student predictions and soft teacher labels\n",
        "  - An alpha factor to weight the student and distillation loss\n",
        "  - An optimizer for the student and metrics to evaluate performance\n",
        "  \"\"\"\n",
        "  def __init__(self, student, teacher):\n",
        "\n",
        "    super(Distiller, self).__init__()\n",
        "    self.teacher = teacher\n",
        "    self.student = student\n",
        "\n",
        "  def compile(self, optimizer, metrics, student_loss_fn, distillation_loss_fn,\n",
        "              alpha=0.1, temperature=3):\n",
        "    \n",
        "    super(Distiller, self).compile(optimizer=optimizer, metrics=metrics)\n",
        "    self.student_loss_fn = student_loss_fn\n",
        "    self.distillation_loss_fn = distillation_loss_fn\n",
        "    self.alpha = alpha\n",
        "    self.temperature = temperature\n",
        "\n",
        "  def train_step(self, data):\n",
        "\n",
        "    # Unpack the data\n",
        "    x, y = data\n",
        "\n",
        "    # Forward pass of teacher\n",
        "    teacher_pred = self.teacher(x, training=False)\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "\n",
        "      # Forward pass of the student \n",
        "      student_pred = self.student(x, training=True)\n",
        "\n",
        "      # Compute losses\n",
        "      student_loss = self.student_loss_fn(y, student_pred)\n",
        "\n",
        "      # Compute scaled distillation loss\n",
        "      distillation_loss = (self.distillation_loss_fn(\n",
        "          tf.nn.softmax(teacher_pred / self.temperature, axis=1),\n",
        "          tf.nn.softmax(student_pred / self.temperature, axis=1),\n",
        "      )\n",
        "      * self.temperature ** 2)\n",
        "\n",
        "      loss = self.alpha * student_loss + (1 - self.alpha) * distillation_loss\n",
        "\n",
        "\n",
        "    # Compute gradients \n",
        "    trainable_vars = self.student.trainable_variables\n",
        "    gradients = tape.gradient(loss, trainable_vars)\n",
        "\n",
        "    # Update weights \n",
        "    self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
        "\n",
        "    # Update the metrics \n",
        "    self.compiled_metrics.update_state(y, student_pred)\n",
        "\n",
        "    # Return a dict of performance\n",
        "    results = {m.name: m.result() for m in self.metrics}\n",
        "    results.update(\n",
        "        {\"student_loss\": student_loss, \"distillation_loss\":distillation_loss}\n",
        "    )\n",
        "\n",
        "    return results\n",
        "\n",
        "  def test_step(self, data):\n",
        "                \n",
        "    # Unpack the data\n",
        "    x, y = data\n",
        "\n",
        "    # Compute predictions \n",
        "    y_prediction = self.student(x, training=False)\n",
        "\n",
        "    # Calculate the loss\n",
        "    student_loss = self.student_loss_fn(y, y_prediction)\n",
        "\n",
        "    # Update the metrics\n",
        "    self.compiled_metrics.update_state(y, y_prediction)\n",
        "\n",
        "    # Return a dict of performance \n",
        "    results = {m.name: m.result() for m in self.metrics}\n",
        "    results.update({\"student_loss\": student_loss})\n",
        "\n",
        "    return results\n"
      ],
      "metadata": {
        "id": "AUHbT8H95nKr"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "teacher = tf.keras.Sequential([\n",
        "                               tf.keras.layers.Input(shape=(32, 32, 3)),\n",
        "                               tf.keras.layers.Conv2D(256, (3,3), 2, padding=\"same\"),\n",
        "                               tf.keras.layers.LeakyReLU(0.2),\n",
        "                               tf.keras.layers.MaxPool2D(2, 1, padding=\"same\"),\n",
        "                               tf.keras.layers.Conv2D(512, 3, 2, padding=\"same\"),\n",
        "                               tf.keras.layers.Flatten(),\n",
        "                               tf.keras.layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "student = tf.keras.Sequential([\n",
        "                               tf.keras.layers.Input(shape=(32, 32, 3)),\n",
        "                               tf.keras.layers.Conv2D(16, (3,3), 2, padding=\"same\"),\n",
        "                               tf.keras.layers.LeakyReLU(0.2),\n",
        "                               tf.keras.layers.MaxPool2D(2, 1, padding=\"same\"),\n",
        "                               tf.keras.layers.Conv2D(32, 3, 2, padding=\"same\"),\n",
        "                               tf.keras.layers.Flatten(),\n",
        "                               tf.keras.layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "# Clone student for later comparison\n",
        "student_scratch = tf.keras.models.clone_model(student)"
      ],
      "metadata": {
        "id": "BFYOhqDkOpnX"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 64\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "# Normalize the data\n",
        "x_train = x_train.astype(\"float32\") / 255.0\n",
        "\n",
        "x_test = x_test.astype(\"float32\") / 255.0\n"
      ],
      "metadata": {
        "id": "YuOZ-JB8PsDO"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqAF8svBQmBE",
        "outputId": "190037d4-af01-4092-f743-c4214d9edf0d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((50000, 32, 32, 3), (50000, 1), (10000, 32, 32, 3), (10000, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train teacher\n",
        "teacher.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "                loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "teacher.fit(x_train, y_train, epochs=10)\n",
        "teacher.evaluate(x_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LgVO_y2CQHCe",
        "outputId": "a51e8c08-1066-43a3-9aea-66f58df5369f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 1.4565 - accuracy: 0.4939\n",
            "Epoch 2/10\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 1.2541 - accuracy: 0.5721\n",
            "Epoch 3/10\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 1.1766 - accuracy: 0.5983\n",
            "Epoch 4/10\n",
            "1563/1563 [==============================] - 15s 10ms/step - loss: 1.1199 - accuracy: 0.6178\n",
            "Epoch 5/10\n",
            "1563/1563 [==============================] - 15s 10ms/step - loss: 1.0837 - accuracy: 0.6287\n",
            "Epoch 6/10\n",
            "1563/1563 [==============================] - 15s 10ms/step - loss: 1.0439 - accuracy: 0.6443\n",
            "Epoch 7/10\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 1.0085 - accuracy: 0.6580\n",
            "Epoch 8/10\n",
            "1563/1563 [==============================] - 15s 10ms/step - loss: 0.9834 - accuracy: 0.6658\n",
            "Epoch 9/10\n",
            "1563/1563 [==============================] - 15s 10ms/step - loss: 0.9474 - accuracy: 0.6799\n",
            "Epoch 10/10\n",
            "1563/1563 [==============================] - 15s 10ms/step - loss: 0.9222 - accuracy: 0.6861\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 1.3371 - accuracy: 0.5970\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.3371248245239258, 0.597000002861023]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now we can distill the teacher to student\n",
        "distiller = Distiller(student=student, teacher=teacher)\n",
        "distiller.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(),\n",
        "    metrics=[\"accuracy\"],\n",
        "    student_loss_fn=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "    distillation_loss_fn=tf.keras.losses.KLDivergence(),\n",
        "    alpha=0.1,\n",
        "    temperature=10\n",
        ")\n",
        "\n",
        "# Distill teacher to student \n",
        "distiller.fit(x_train, y_train, epochs=10)\n",
        "\n",
        "# Evaluate student on test dataset\n",
        "distiller.evaluate(x_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xiQp4IxrQhIq",
        "outputId": "9ae5e024-db81-4207-b075-3aec813cd3d4"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1563/1563 [==============================] - 9s 5ms/step - accuracy: 0.4656 - student_loss: 1.5224 - distillation_loss: 0.0180\n",
            "Epoch 2/10\n",
            "1563/1563 [==============================] - 8s 5ms/step - accuracy: 0.5662 - student_loss: 1.2484 - distillation_loss: 0.0132\n",
            "Epoch 3/10\n",
            "1563/1563 [==============================] - 8s 5ms/step - accuracy: 0.5914 - student_loss: 1.1795 - distillation_loss: 0.0120\n",
            "Epoch 4/10\n",
            "1563/1563 [==============================] - 8s 5ms/step - accuracy: 0.6043 - student_loss: 1.1413 - distillation_loss: 0.0114\n",
            "Epoch 5/10\n",
            "1563/1563 [==============================] - 8s 5ms/step - accuracy: 0.6145 - student_loss: 1.1121 - distillation_loss: 0.0108\n",
            "Epoch 6/10\n",
            "1563/1563 [==============================] - 8s 5ms/step - accuracy: 0.6252 - student_loss: 1.0859 - distillation_loss: 0.0104\n",
            "Epoch 7/10\n",
            "1563/1563 [==============================] - 8s 5ms/step - accuracy: 0.6345 - student_loss: 1.0620 - distillation_loss: 0.0101\n",
            "Epoch 8/10\n",
            "1563/1563 [==============================] - 8s 5ms/step - accuracy: 0.6383 - student_loss: 1.0456 - distillation_loss: 0.0099\n",
            "Epoch 9/10\n",
            "1563/1563 [==============================] - 8s 5ms/step - accuracy: 0.6436 - student_loss: 1.0303 - distillation_loss: 0.0097\n",
            "Epoch 10/10\n",
            "1563/1563 [==============================] - 8s 5ms/step - accuracy: 0.6481 - student_loss: 1.0208 - distillation_loss: 0.0096\n",
            "313/313 [==============================] - 1s 2ms/step - accuracy: 0.6205 - student_loss: 1.1166\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6205000281333923, 0.923244833946228]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train student from scratch for comparison\n",
        "student_scratch.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(),\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "student_scratch.fit(x_train, y_train, epochs=10)\n",
        "student_scratch.evaluate(x_test,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cOl7soU-R_nN",
        "outputId": "f50a9ce3-949a-4611-92f8-96ca0c2c2fb5"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.5603 - accuracy: 0.4498\n",
            "Epoch 2/10\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.3166 - accuracy: 0.5418\n",
            "Epoch 3/10\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2366 - accuracy: 0.5710\n",
            "Epoch 4/10\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1840 - accuracy: 0.5906\n",
            "Epoch 5/10\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1419 - accuracy: 0.6054\n",
            "Epoch 6/10\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1125 - accuracy: 0.6157\n",
            "Epoch 7/10\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0809 - accuracy: 0.6274\n",
            "Epoch 8/10\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0622 - accuracy: 0.6345\n",
            "Epoch 9/10\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0491 - accuracy: 0.6375\n",
            "Epoch 10/10\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.0350 - accuracy: 0.6448\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 1.1153 - accuracy: 0.6187\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.1153295040130615, 0.6187000274658203]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "SooRJUZkTON_"
      },
      "execution_count": 25,
      "outputs": []
    }
  ]
}